{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "os.chdir('..')\n",
    "\n",
    "import dataset\n",
    "from model_part import conv2d\n",
    "from model_part import fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "today = datetime.strftime(datetime.now(), '%d%m%y')\n",
    "flags.DEFINE_integer('batch_size', 8, 'Batch size')\n",
    "flags.DEFINE_string('train_file', 'train.csv', 'Train file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(inputs, is_training, reuse=False, keep_drop=0.5, trainable=True,\n",
    "          debug=False):\n",
    "    \"\"\"Create an upscaled Eigen coarse model.\n",
    "\n",
    "    inputs.get_shape() = TensorShape([Dimension(8), Dimension(228),\n",
    "                                      Dimension(304), Dimension(3)])\n",
    "    \"\"\"\n",
    "    # Normalize.\n",
    "    inputs = (inputs - dataset.IMAGES_MEAN) * dataset.IMAGES_ISTD\n",
    "    net = conv2d('conv1', inputs, [11, 11, 3, 96], [96], [1, 4, 4, 1],\n",
    "                 padding='VALID', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv1_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='VALID', name='pool1')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net1 = tf.nn.relu(net, name='relu1')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net1.name, net1.get_shape()))\n",
    "\n",
    "    net = conv2d('conv2', net1, [5, 5, 96, 256], [256], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv2_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='VALID', name='pool2')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net2 = tf.nn.relu(net, name='relu2')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net2.name, net2.get_shape()))\n",
    "\n",
    "    net = conv2d('conv3', net2, [3, 3, 256, 384], [384], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv3_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='relu3')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = conv2d('conv4', net, [3, 3, 384, 384], [384], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv4_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net4 = tf.nn.relu(net, name='relu4')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net4.name, net4.get_shape()))\n",
    "\n",
    "    net = conv2d('conv5', net4, [3, 3, 384, 256], [256], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv5_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='VALID', name='pool5')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='relu5')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.layers.batch_normalization(net, axis=1, training=is_training,\n",
    "                                        name='fc6_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = fc('fc6', net, [6*8*256, 4096], [4096], reuse=reuse,\n",
    "             activation='relu', trainable=trainable)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.dropout(net, keep_drop)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.layers.batch_normalization(net, axis=1, training=is_training,\n",
    "                                        name='fc7_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = fc('fc7', net, [4096, 6*8*256], [6*8*256], reuse=reuse,\n",
    "             activation='relu', trainable=trainable)\n",
    "    if debug:\n",
    "            print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.dropout(net, keep_drop)\n",
    "    if debug:\n",
    "        print('%s \\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.reshape(net, [-1, 6, 8, 256])\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[13, 17],\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "    net = conv2d('up1', net, [3, 3, 256, 384], [384], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    # net = conv2d('up1_1', net, [3, 3, 384, 384], [384], [1, 1, 1, 1],\n",
    "    #              padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "    #              activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up1_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='up1_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = net + net4\n",
    "    if debug:\n",
    "        print('%s \\t\\t\\t%s' % (net.name, net.get_shape()))\n",
    "    # net = tf.image.resize_images(net, size=[23, 32],\n",
    "    #                              method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    # if debug:\n",
    "    #     print('%s \\t%s' % (net.name, net.get_shape()))\n",
    "    net = conv2d('up2', net, [3, 3, 384, 256], [256], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    # net = conv2d('up2_1', net, [3, 3, 256, 256], [256], [1, 1, 1, 1],\n",
    "    #              padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "    #              activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up2_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='up2_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = net + net2\n",
    "\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.image.resize_images(net, size=[27, 36],\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "    net = conv2d('up3', net, [3, 3, 256, 96], [96], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    # net = conv2d('up3_1', net, [3, 3, 96, 96], [96], [1, 1, 1, 1],\n",
    "    #              padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "    #              activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up3_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='up3_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = net + net1\n",
    "\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[55, 74],\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "    net = conv2d('up4', net, [3, 3, 96, 48], [48], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    # net = conv2d('up4_1', net, [3, 3, 48, 48], [48], [1, 1, 1, 1],\n",
    "    #              padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "    #              activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up4_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='up4_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[111, 150],\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "    net = conv2d('up5', net, [3, 3, 48, 24], [24], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    # net = conv2d('up5_1', net, [3, 3, 24, 24], [24], [1, 1, 1, 1],\n",
    "    #              padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "    #              activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up5_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='up5_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.image.resize_images(net, size=[228, 304],\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "    net = conv2d('up6', net, [3, 3, 24, 1], [1], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    # net = conv2d('up6_1', net, [3, 3, 1, 1], [1], [1, 1, 1, 1],\n",
    "    #              padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "    #              activation=None)\n",
    "\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/conv1:0 \t\t(8, 55, 74, 96)\n",
      "conv1_bn/batchnorm/add_1:0(8, 55, 74, 96)\n",
      "pool1:0 \t\t(8, 27, 36, 96)\n",
      "relu1:0 \t\t(8, 27, 36, 96)\n",
      "conv2/conv2:0 \t\t(8, 27, 36, 256)\n",
      "conv2_bn/batchnorm/add_1:0(8, 27, 36, 256)\n",
      "pool2:0 \t\t(8, 13, 17, 256)\n",
      "relu2:0 \t\t(8, 13, 17, 256)\n",
      "conv3/conv3:0 \t\t(8, 13, 17, 384)\n",
      "conv3_bn/batchnorm/add_1:0(8, 13, 17, 384)\n",
      "relu3:0 \t\t(8, 13, 17, 384)\n",
      "conv4/conv4:0 \t\t(8, 13, 17, 384)\n",
      "conv4_bn/batchnorm/add_1:0(8, 13, 17, 384)\n",
      "relu4:0 \t\t(8, 13, 17, 384)\n",
      "conv5/conv5:0 \t\t(8, 13, 17, 256)\n",
      "conv5_bn/batchnorm/add_1:0(8, 13, 17, 256)\n",
      "pool5:0 \t\t(8, 6, 8, 256)\n",
      "relu5:0 \t\t(8, 6, 8, 256)\n",
      "fc6_bn/batchnorm/add_1:0(8, 6, 8, 256)\n",
      "fc6/fc6_1:0 \t\t(8, 4096)\n",
      "dropout/mul:0 \t\t(8, 4096)\n",
      "fc7_bn/batchnorm/add_1:0(8, 4096)\n",
      "fc7/fc7_1:0 \t\t(8, 12288)\n",
      "dropout_1/mul:0 \t(8, 12288)\n",
      "Reshape_1:0 \t\t(8, 6, 8, 256)\n",
      "ResizeNearestNeighbor:0 (8, 13, 17, 256)\n",
      "up1/up1:0 \t\t(8, 13, 17, 384)\n",
      "up1_bn/batchnorm/add_1:0(8, 13, 17, 384)\n",
      "up1_relu:0 \t\t(8, 13, 17, 384)\n",
      "add:0 \t\t\t(8, 13, 17, 384)\n",
      "up2/up2:0 \t\t(8, 13, 17, 256)\n",
      "up2_bn/batchnorm/add_1:0(8, 13, 17, 256)\n",
      "up2_relu:0 \t\t(8, 13, 17, 256)\n",
      "add_1:0 \t\t(8, 13, 17, 256)\n",
      "ResizeNearestNeighbor_1:0 (8, 27, 36, 256)\n",
      "up3/up3:0 \t\t(8, 27, 36, 96)\n",
      "up3_bn/batchnorm/add_1:0(8, 27, 36, 96)\n",
      "up3_relu:0 \t\t(8, 27, 36, 96)\n",
      "add_2:0 \t\t(8, 27, 36, 96)\n",
      "ResizeNearestNeighbor_2:0 (8, 55, 74, 96)\n",
      "up4/up4:0 \t\t(8, 55, 74, 48)\n",
      "up4_bn/batchnorm/add_1:0(8, 55, 74, 48)\n",
      "up4_relu:0 \t\t(8, 55, 74, 48)\n",
      "ResizeNearestNeighbor_3:0 (8, 111, 150, 48)\n",
      "up5/up5:0 \t\t(8, 111, 150, 24)\n",
      "up5_bn/batchnorm/add_1:0(8, 111, 150, 24)\n",
      "up5_relu:0 \t\t(8, 111, 150, 24)\n",
      "ResizeNearestNeighbor_4:0 (8, 228, 304, 24)\n",
      "up6/up6:0 \t\t(8, 228, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    ds = dataset.DataSet(FLAGS.batch_size)\n",
    "    images, depths, _ = ds.csv_inputs(FLAGS.train_file,\n",
    "                                               target_size=[228, 304])\n",
    "    keep_drop = tf.placeholder(tf.float32)\n",
    "    encoder_model = model(images, is_training=True, keep_drop=keep_drop,\n",
    "                          debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_model(inputs, is_training, reuse=False, keep_drop=0.5, trainable=True,\n",
    "          debug=False):\n",
    "    \"\"\"Create an upscaled Eigen coarse model.\n",
    "\n",
    "    inputs.get_shape() = TensorShape([Dimension(8), Dimension(228),\n",
    "                                      Dimension(304), Dimension(3)])\n",
    "    \"\"\"\n",
    "    # Normalize.\n",
    "    inputs = (inputs - dataset.IMAGES_MEAN) * dataset.IMAGES_ISTD\n",
    "    net = conv2d('conv1', inputs, [11, 11, 3, 96], [96], [1, 4, 4, 1],\n",
    "                 padding='VALID', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv1_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='VALID', name='pool1')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net1 = tf.nn.relu(net, name='relu1')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net1.name, net1.get_shape()))\n",
    "\n",
    "    net = conv2d('conv2', net1, [5, 5, 96, 256], [256], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv2_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='VALID', name='pool2')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net2 = tf.nn.relu(net, name='relu2')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net2.name, net2.get_shape()))\n",
    "\n",
    "    net = conv2d('conv3', net2, [3, 3, 256, 384], [384], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv3_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='relu3')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = conv2d('conv4', net, [3, 3, 384, 384], [384], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv4_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net4 = tf.nn.relu(net, name='relu4')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net4.name, net4.get_shape()))\n",
    "\n",
    "    net = conv2d('conv5', net4, [3, 3, 384, 256], [256], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='conv5_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.max_pool(net, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='VALID', name='pool5')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.relu(net, name='relu5')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.layers.batch_normalization(net, axis=1, training=is_training,\n",
    "                                        name='fc6_bn')\n",
    "    if debug:\n",
    "        print('\\n%s%s' % (net.name, net.get_shape()))\n",
    "    net = fc('fc6', net, [6*8*256, 4096], [4096], reuse=reuse,\n",
    "             activation='relu', trainable=trainable)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.dropout(net, keep_drop)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.layers.batch_normalization(net, axis=1, training=is_training,\n",
    "                                        name='fc7_bn')\n",
    "    if debug:\n",
    "        print('\\n%s%s' % (net.name, net.get_shape()))\n",
    "    net = fc('fc7', net, [4096, 6*8*256], [6*8*256], reuse=reuse,\n",
    "             activation='relu', trainable=trainable)\n",
    "    if debug:\n",
    "            print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.nn.dropout(net, keep_drop)\n",
    "    if debug:\n",
    "        print('%s \\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.reshape(net, [-1, 6, 8, 256])\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[13, 17],\n",
    "                                 method=tf.image.ResizeMethod.BILINEAR)\n",
    "    if debug:\n",
    "        print('\\n%s %s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # upscale conv layer 1\n",
    "    net = conv2d('up1', net, [3, 3, 256, 384], [384], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up1_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    unet1 = tf.nn.relu(net, name='up1_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (unet1.name, unet1.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = net4 + unet1\n",
    "    if debug:\n",
    "        print('%s \\t\\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # upscale conv layer 2\n",
    "    net = conv2d('up2', net, [3, 3, 384, 256], [256], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up2_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    unet2 = tf.nn.relu(net, name='up2_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (unet2.name, unet2.get_shape()))\n",
    "\n",
    "    # skips\n",
    "    unet1_ = conv2d('up3_unet1_skip', unet1, [3, 3, 384, 256], [256],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet1_.name, unet1_.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = net2 + unet1_ + unet2\n",
    "\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.image.resize_images(net, size=[27, 36],\n",
    "                                 method=tf.image.ResizeMethod.BILINEAR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # upscale conv layer 3\n",
    "    net = conv2d('up3', net, [3, 3, 256, 96], [96], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up3_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    unet3 = tf.nn.relu(net, name='up3_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (unet3.name, unet3.get_shape()))\n",
    "\n",
    "    # skips\n",
    "    unet1_ = tf.image.resize_images(unet1, size=[27, 36],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet1_ = conv2d('up4_unet1_skip', unet1_, [3, 3, 384, 96], [96],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet1_.name, unet1_.get_shape()))\n",
    "    unet2_ = tf.image.resize_images(unet2, size=[27, 36],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet2_ = conv2d('up4_unet2_skip', unet2_, [3, 3, 256, 96], [96],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet2_.name, unet2_.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = net1 + unet1_ + unet2_ + unet3\n",
    "\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[55, 74],\n",
    "                                 method=tf.image.ResizeMethod.BILINEAR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # upscale conv layer 4\n",
    "    net = conv2d('up4', net, [3, 3, 96, 48], [48], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up4_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    unet4 = tf.nn.relu(net, name='up4_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (unet4.name, unet4.get_shape()))\n",
    "\n",
    "    # skips\n",
    "    unet1_ = tf.image.resize_images(unet1, size=[55, 74],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet1_ = conv2d('up5_unet1_skip', unet1_, [3, 3, 384, 48], [48],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet1_.name, unet1_.get_shape()))\n",
    "    unet2_ = tf.image.resize_images(unet2, size=[55, 74],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet2_ = conv2d('up5_unet2_skip', unet2_, [3, 3, 256, 48], [48],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet2_.name, unet2_.get_shape()))\n",
    "    unet3_ = tf.image.resize_images(unet3, size=[55, 74],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet3_ = conv2d('up5_unet3_skip', unet3_, [3, 3, 96, 48], [48],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet3_.name, unet3_.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = unet1_ + unet2_ + unet3_ + unet4\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[111, 150],\n",
    "                                 method=tf.image.ResizeMethod.BILINEAR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # upscale conv layer 5\n",
    "    net = conv2d('up5', net, [3, 3, 48, 24], [24], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    net = tf.layers.batch_normalization(net, axis=3, training=is_training,\n",
    "                                        name='up5_bn')\n",
    "    if debug:\n",
    "        print('%s%s' % (net.name, net.get_shape()))\n",
    "    unet5 = tf.nn.relu(net, name='up5_relu')\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (unet5.name, unet5.get_shape()))\n",
    "\n",
    "    # skips\n",
    "    unet1_ = tf.image.resize_images(unet1, size=[111, 150],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet1_ = conv2d('up6_unet1_skip', unet1_, [3, 3, 384, 24], [24],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet1_.name, unet1_.get_shape()))\n",
    "    unet2_ = tf.image.resize_images(unet2, size=[111, 150],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet2_ = conv2d('up6_unet2_skip', unet2_, [3, 3, 256, 24], [24],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet2_.name, unet2_.get_shape()))\n",
    "    unet3_ = tf.image.resize_images(unet3, size=[111, 150],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet3_ = conv2d('up6_unet3_skip', unet3_, [3, 3, 96, 24], [24],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet3_.name, unet3_.get_shape()))\n",
    "    unet4_ = tf.image.resize_images(unet4, size=[111, 150],\n",
    "                                    method=tf.image.ResizeMethod.BILINEAR)\n",
    "    unet4_ = conv2d('up6_unet4_skip', unet4_, [3, 3, 48, 24], [24],\n",
    "                    [1, 1, 1, 1], padding='SAME', reuse=reuse,\n",
    "                    trainable=trainable, wd=0.0005, activation=None)\n",
    "    if debug:\n",
    "        print('%s%s' % (unet4_.name, unet4_.get_shape()))\n",
    "\n",
    "    # residual\n",
    "    net = unet1_ + unet2_ + unet3_ + unet4_ + unet5\n",
    "    if debug:\n",
    "        print('%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "\n",
    "    net = tf.image.resize_images(net, size=[228, 304],\n",
    "                                 method=tf.image.ResizeMethod.BILINEAR)\n",
    "    if debug:\n",
    "        print('%s %s' % (net.name, net.get_shape()))\n",
    "\n",
    "    # upscale conv layer 6\n",
    "    net = conv2d('up6', net, [3, 3, 24, 1], [1], [1, 1, 1, 1],\n",
    "                 padding='SAME', reuse=reuse, trainable=trainable, wd=0.0005,\n",
    "                 activation=None)\n",
    "\n",
    "    if debug:\n",
    "        print('\\n%s \\t\\t%s' % (net.name, net.get_shape()))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/conv1:0 \t\t(8, 55, 74, 96)\n",
      "conv1_bn/batchnorm/add_1:0(8, 55, 74, 96)\n",
      "pool1:0 \t\t(8, 27, 36, 96)\n",
      "relu1:0 \t\t(8, 27, 36, 96)\n",
      "\n",
      "conv2/conv2:0 \t\t(8, 27, 36, 256)\n",
      "conv2_bn/batchnorm/add_1:0(8, 27, 36, 256)\n",
      "pool2:0 \t\t(8, 13, 17, 256)\n",
      "relu2:0 \t\t(8, 13, 17, 256)\n",
      "\n",
      "conv3/conv3:0 \t\t(8, 13, 17, 384)\n",
      "conv3_bn/batchnorm/add_1:0(8, 13, 17, 384)\n",
      "relu3:0 \t\t(8, 13, 17, 384)\n",
      "\n",
      "conv4/conv4:0 \t\t(8, 13, 17, 384)\n",
      "conv4_bn/batchnorm/add_1:0(8, 13, 17, 384)\n",
      "relu4:0 \t\t(8, 13, 17, 384)\n",
      "\n",
      "conv5/conv5:0 \t\t(8, 13, 17, 256)\n",
      "conv5_bn/batchnorm/add_1:0(8, 13, 17, 256)\n",
      "pool5:0 \t\t(8, 6, 8, 256)\n",
      "relu5:0 \t\t(8, 6, 8, 256)\n",
      "\n",
      "fc6_bn/batchnorm/add_1:0(8, 6, 8, 256)\n",
      "fc6/fc6_1:0 \t\t(8, 4096)\n",
      "dropout/mul:0 \t\t(8, 4096)\n",
      "\n",
      "fc7_bn/batchnorm/add_1:0(8, 4096)\n",
      "fc7/fc7_1:0 \t\t(8, 12288)\n",
      "dropout_1/mul:0 \t(8, 12288)\n",
      "Reshape_1:0 \t\t(8, 6, 8, 256)\n",
      "\n",
      "ResizeBilinear_2:0 (8, 13, 17, 256)\n",
      "up1/up1:0 \t\t(8, 13, 17, 384)\n",
      "up1_bn/batchnorm/add_1:0(8, 13, 17, 384)\n",
      "up1_relu:0 \t\t(8, 13, 17, 384)\n",
      "add:0 \t\t\t(8, 13, 17, 384)\n",
      "\n",
      "up2/up2:0 \t\t(8, 13, 17, 256)\n",
      "up2_bn/batchnorm/add_1:0(8, 13, 17, 256)\n",
      "up2_relu:0 \t\t(8, 13, 17, 256)\n",
      "up3_unet1_skip/up3_unet1_skip:0(8, 13, 17, 256)\n",
      "add_2:0 \t\t(8, 13, 17, 256)\n",
      "ResizeBilinear_3:0 (8, 27, 36, 256)\n",
      "\n",
      "up3/up3:0 \t\t(8, 27, 36, 96)\n",
      "up3_bn/batchnorm/add_1:0(8, 27, 36, 96)\n",
      "up3_relu:0 \t\t(8, 27, 36, 96)\n",
      "up4_unet1_skip/up4_unet1_skip:0(8, 27, 36, 96)\n",
      "up4_unet2_skip/up4_unet2_skip:0(8, 27, 36, 96)\n",
      "add_5:0 \t\t(8, 27, 36, 96)\n",
      "ResizeBilinear_6:0 (8, 55, 74, 96)\n",
      "\n",
      "up4/up4:0 \t\t(8, 55, 74, 48)\n",
      "up4_bn/batchnorm/add_1:0(8, 55, 74, 48)\n",
      "up4_relu:0 \t\t(8, 55, 74, 48)\n",
      "up5_unet1_skip/up5_unet1_skip:0(8, 55, 74, 48)\n",
      "up5_unet2_skip/up5_unet2_skip:0(8, 55, 74, 48)\n",
      "up5_unet3_skip/up5_unet3_skip:0(8, 55, 74, 48)\n",
      "add_8:0 \t\t(8, 55, 74, 48)\n",
      "ResizeBilinear_10:0 (8, 111, 150, 48)\n",
      "\n",
      "up5/up5:0 \t\t(8, 111, 150, 24)\n",
      "up5_bn/batchnorm/add_1:0(8, 111, 150, 24)\n",
      "up5_relu:0 \t\t(8, 111, 150, 24)\n",
      "up6_unet1_skip/up6_unet1_skip:0(8, 111, 150, 24)\n",
      "up6_unet2_skip/up6_unet2_skip:0(8, 111, 150, 24)\n",
      "up6_unet3_skip/up6_unet3_skip:0(8, 111, 150, 24)\n",
      "up6_unet4_skip/up6_unet4_skip:0(8, 111, 150, 24)\n",
      "add_12:0 \t\t(8, 111, 150, 24)\n",
      "ResizeBilinear_15:0 (8, 228, 304, 24)\n",
      "\n",
      "up6/up6:0 \t\t(8, 228, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    ds = dataset.DataSet(FLAGS.batch_size)\n",
    "    images, depths, _ = ds.csv_inputs(FLAGS.train_file,\n",
    "                                               target_size=[228, 304])\n",
    "    keep_drop = tf.placeholder(tf.float32)\n",
    "    encoder_model = dense_model(images, is_training=True, keep_drop=keep_drop,\n",
    "                          debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
